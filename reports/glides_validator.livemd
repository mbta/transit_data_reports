# Glides Terminal Prediction Accuracy

```elixir
Mix.install(
  [
    {:atomic_map, "~> 0.9.3"},
    {:csv, "~> 3.2"},
    {:kino, "~> 0.12.0"},
    {:ex_aws, "~> 2.5"},
    {:ex_aws_s3, "~> 2.5"},
    {:hackney, "~> 1.20"},
    {:sweet_xml, "~> 0.7.4"},
    {:timex, "~> 3.7"},
    {:tzdata, "~> 1.1"},
    {:jaxon, "~> 2.0"}
  ],
  config: [
    ex_aws: [
      access_key_id: System.get_env("LB_AWS_ACCESS_KEY_ID"),
      secret_access_key: System.get_env("LB_AWS_SECRET_ACCESS_KEY"),
      region: "us-east-1"
    ]
  ]
)
```

## Options for Report

### README

This report provides an implementation of https://www.notion.so/mbta-downtown-crossing/Rethinking-Prediction-Accuracy-for-Glides-e99561127b01490689135ab6b70cd33c

<!-- livebook:{"reevaluate_automatically":true} -->

```elixir
# Groups of stop IDs

boston_college = ["70106"]
cleveland_circle = ["70238"]
riverside = ["70160", "70161"]
heath_street = ["70260"]
union_square = ["70503", "70504"]
medford_tufts = ["70511", "70512"]

gl_terminal_stop_ids =
  [boston_college, cleveland_circle, riverside, heath_street, union_square, medford_tufts]
  |> List.flatten()

gl_western_terminal_stop_ids =
  [boston_college, cleveland_circle, riverside, heath_street]
  |> List.flatten()

gl_northern_terminal_stop_ids =
  [union_square, medford_tufts]
  |> List.flatten()

ashmont = ["70261"]
mattapan = ["70276"]
m_terminal_stop_ids = List.flatten([ashmont, mattapan])

all_light_rail_stop_ids = List.flatten([gl_terminal_stop_ids, m_terminal_stop_ids])

# Inverts a map with MapSets for values.
# Set elements become values and keys get put into sets.
# iex> invert_map_of_sets.(%{a: set([:b, :c]), d: set([:c]), e: set([])})
# %{b: set([:a]), c: set([:a, :d])}
invert_map_of_sets = fn m ->
  m
  |> Enum.flat_map(fn {k, sets} -> Enum.map(sets, &{k, &1}) end)
  |> Enum.group_by(fn {_k, v} -> v end, fn {k, _v} -> k end)
  |> Map.new(fn {k, vs} -> {k, MapSet.new(vs)} end)
end

first_to_next_stop =
  %{
    # Boston College -> South Street
    "70106" => ["70110"],
    # Cleveland Circle -> Englewood Avenue
    "70238" => ["70236"],
    # Riverside (2) -> Woodland
    "70160" => ["70162"],
    "70161" => ["70162"],
    # Heath Street -> Back of the Hill
    "70260" => ["70258"],
    # Union Square (2) -> Lechmere
    "70503" => ["70502"],
    "70504" => ["70502"],
    # Medford/Tufts (2) -> Ball Square
    "70511" => ["70510"],
    "70512" => ["70510"],
    # Ashmont -> Cedar Grove
    "70261" => ["70263"],
    # Mattapan -> Capen Street
    "70276" => ["70274"]
  }
  |> Map.new(fn {k, list} -> {k, MapSet.new(list)} end)

next_to_first_stop = invert_map_of_sets.(first_to_next_stop)

env_input =
  Kino.Input.select("Environment", [
    {"", "prod"},
    {"-dev-blue", "dev-blue"},
    {"-dev-green", "dev-green"},
    {"-dev", "dev"},
    {"-sandbox", "sandbox"}
  ])

yesterday_eastern = DateTime.now!("America/New_York") |> DateTime.to_date() |> Date.add(-1)
date_input = Kino.Input.date("Date", default: yesterday_eastern)

line_input =
  Kino.Input.select("Line", [
    {nil, "(Don't filter by line)"},
    {"Green Line", "Green Line"},
    {"Mattapan Line", "Mattapan Line"}
  ])

stop_ids_input =
  Kino.Input.select("Stop(s)", [
    {nil, "(Don't filter by stop)"},
    {all_light_rail_stop_ids, "All light rail terminal stops"},
    {gl_terminal_stop_ids, "All Green Line terminal stops"},
    {m_terminal_stop_ids, "All Mattapan terminal stops"},
    {gl_western_terminal_stop_ids, "Western Green Line terminal stops"},
    {gl_northern_terminal_stop_ids, "Northern GL terminal stops"},
    {boston_college, "Boston College"},
    {cleveland_circle, "Cleveland Circle"},
    {riverside, "Riverside"},
    {heath_street, "Heath Street"},
    {union_square, "Union Square"},
    {medford_tufts, "Medford/Tufts"},
    {ashmont, "Ashmont"},
    {mattapan, "Mattapan"}
  ])

limit_to_next_2_predictions_input = Kino.Input.checkbox("Consider next 2 predictions only")

[
  env_input,
  date_input,
  line_input,
  stop_ids_input,
  limit_to_next_2_predictions_input
]
|> Enum.each(&Kino.render/1)
```

## Function definitions

All the implementation logic for the report.

Collapse this section to skip to the procedure and outputs.

---

---

---

<!-- livebook:{"break_markdown":true} -->

A struct to hold user-defined settings.

```elixir
defmodule GlidesReport.Settings do
  @moduledoc "User-selected settings for the report."

  @type t :: %__MODULE__{
          env_suffix: String.t(),
          date: Date.t(),
          line: String.t() | nil,
          stop_ids: list(String.t()) | nil,
          limit_to_next_2_predictions: boolean
        }

  defstruct [
    :env_suffix,
    :date,
    :line,
    :stop_ids,
    :limit_to_next_2_predictions
  ]

  # Parses settings from input elements.
  def new(env, date, line, stop_ids, limit_to_next_2_predictions) do
    %__MODULE__{
      env_suffix: Kino.Input.read(env),
      date: Kino.Input.read(date),
      line: Kino.Input.read(line),
      stop_ids: Kino.Input.read(stop_ids),
      limit_to_next_2_predictions: Kino.Input.read(limit_to_next_2_predictions)
    }
    |> tap(fn settings -> if is_nil(settings.date), do: raise("A date must be selected") end)
  end
end
```

Utility functions.

```elixir
defmodule GlidesReport.Util do
  @first_to_next_stop first_to_next_stop

  defp first_to_next_stop do
    @first_to_next_stop
  end

  # Streams all values from an ETS table. (Assuming table's objects are {key, value} 2-tuples)
  def stream_values(table) do
    :ets.first(table)
    |> Stream.iterate(fn key -> :ets.next(table, key) end)
    |> Stream.take_while(fn key -> key != :"$end_of_table" end)
    |> Stream.map(fn key -> :ets.lookup_element(table, key, 2) end)
  end

  def on_line?(nil, _route_id), do: true

  def on_line?("Green Line", route_id) do
    String.starts_with?(route_id, "Green-")
  end

  def on_line?("Mattapan Line", route_id) do
    route_id == "Mattapan"
  end

  def zero_pad(n, count \\ 2) do
    n
    |> Integer.to_string()
    |> String.pad_leading(count, "0")
  end

  def unix_timestamp_to_local_hour(timestamp) do
    timestamp
    |> DateTime.from_unix!()
    |> DateTime.shift_zone!("America/New_York")
    |> then(& &1.hour)
  end

  def unix_timestamp_to_local_minute(timestamp) do
    timestamp
    |> DateTime.from_unix!()
    |> DateTime.shift_zone!("America/New_York")
    |> then(& &1.minute)
  end

  def relevant_trip_update?(tr_upd) do
    Enum.all?(
      [
        [:trip_update, :trip, :route_id],
        [:trip_update, :stop_time_update, Access.all(), :stop_id],
        [:trip_update, :timestamp]
      ],
      &(not is_nil(get_in(tr_upd, &1)))
    ) and
      tr_upd[:trip_update][:trip][:revenue]
  end

  def filter_stops(tr_upd, stop_ids) do
    case filter_stops_by_stop_id(tr_upd, stop_ids) do
      nil ->
        nil

      tr_upd ->
        update_in(tr_upd.trip_update.stop_time_update, fn stop_time_update ->
          Enum.reject(stop_time_update, &is_nil(get_in(&1, [:departure, :time])))
        end)
    end
  end

  # Removes, from a trip update's stop_time_update, all entries that don't apply to the target stop(s).
  # Returns nil if trip update doesn't contain the target stop anywhere in its stop_time_update.
  defp filter_stops_by_stop_id(tr_upd, nil), do: tr_upd

  defp filter_stops_by_stop_id(tr_upd, stop_ids) do
    tr_upd.trip_update.stop_time_update
    |> Enum.find(&(&1.stop_id in stop_ids))
    |> case do
      nil ->
        nil

      target_stop_time_update ->
        put_in(tr_upd.trip_update.stop_time_update, [target_stop_time_update])
    end
  end

  def relevant_vehicle_position?(ve_pos) do
    has_required_fields =
      Enum.all?(
        [
          [:vehicle, :timestamp],
          [:vehicle, :current_status],
          [:vehicle, :stop_id]
        ],
        &(not is_nil(get_in(ve_pos, &1)))
      )

    is_revenue = ve_pos[:vehicle][:trip][:revenue]
    is_departing = ve_pos[:vehicle][:current_status] == "IN_TRANSIT_TO"

    has_required_fields and is_revenue and is_departing
  end

  def vehicle_departing_target_stop?(_status_stop, nil), do: true

  def vehicle_departing_target_stop?(stop_id, target_stop_ids) do
    Enum.any?(target_stop_ids, fn target_stop ->
      stop_id in Map.fetch!(first_to_next_stop(), target_stop)
    end)
  end

  # Converts a nonempty list of KW-lists, e.g.:
  # [
  #   [{"headerA", "valueA1"}, {"headerB", "valueB1"}],
  #   [{"headerA", "valueA2"}, {"headerB", "valueB2"}]
  # ]
  # to a CSV string.
  def table_to_csv(table) do
    table
    |> Stream.map(&Map.new/1)
    |> CSV.encode(headers: Enum.map(hd(table), &elem(&1, 0)), delimiter: "\n")
    |> Enum.join()
  end

  def build_csv_name(table_name, settings) do
    %{
      env_suffix: env_suffix,
      date: date,
      line: line,
      stop_ids: stop_ids,
      limit_to_next_2_predictions: limit_to_next_2_predictions
    } = settings

    env = if env_suffix == "", do: "prod", else: String.slice(env_suffix, 1..-1//1)

    optionals =
      [
        {line, "line=#{line}"},
        {stop_ids, "stop_ids=#{inspect(stop_ids)}"},
        {limit_to_next_2_predictions, "next 2 predictions only"}
      ]
      |> Enum.filter(&elem(&1, 0))
      |> Enum.map(&elem(&1, 1))
      |> Enum.join(",")
      |> case do
        "" -> ""
        str -> ",#{str}"
      end

    "Glides report - #{table_name} - #{env},#{date}#{optionals}.csv"
  end
end
```

Logic for loading trip update and vehicle position data.

```elixir
defmodule GlidesReport.Loader do
  def load_data(date, env_suffix) do
    set_up_table(:TripUpdates)
    set_up_table(:VehiclePositions)

    File.mkdir_p!(local_dir(env_suffix))

    # Create the inferred start and end times:
    start_time = DateTime.new!(date, Time.new!(4, 0, 0), "America/New_York")

    end_time =
      DateTime.new!(date, Time.new!(3, 59, 59), "America/New_York")
      # Can be replaced with DateTime.shift/2 once Livebook runs on Elixir 1.17+
      |> Timex.shift(days: 1)

    # Calculate the total number of 5-minute increments in a day
    total_increments = div(DateTime.diff(end_time, start_time, :minute), 5)

    # Shift start_time to UTC to align with the UTC timestamps used in our S3 object names
    start_time_utc = DateTime.shift_zone!(start_time, "Etc/UTC")

    # Create list of path/to/file prefixes for each 5-minute increment
    path_prefixes =
      Enum.map(0..total_increments, fn increment ->
        start_time_utc
        |> DateTime.add(increment * 5, :minute)
        |> Calendar.strftime("%Y/%m/%d/%Y-%m-%dT%H:%M")
      end)

    local_files = File.ls!(local_dir(env_suffix))

    frame = Kino.Frame.new() |> Kino.render()

    [
      populate_table(:TripUpdates, path_prefixes, env_suffix, local_files),
      populate_table(:VehiclePositions, path_prefixes, env_suffix, local_files)
    ]
    |> Enum.each(fn table -> Kino.Frame.append(frame, table) end)
  end

  # Loads data into a table and creates a UI element representing the table.
  defp populate_table(table_name, path_prefixes, env_suffix, local_files) do
    path_prefixes
    |> Stream.map(&fetch_local_path(&1, table_name, local_files))
    |> Task.async_stream(fn
      {:ok, filename} ->
        local_path = Path.join(local_dir(env_suffix), filename)
        load_file_into_table(table_name, local_path)

      {:error, path_prefix} ->
        local_path = download_file(path_prefix, table_name, env_suffix)
        load_file_into_table(table_name, local_path)
    end)
    |> Stream.run()

    Kino.ETS.new(table_name)
  end

  defp local_dir(""), do: Path.join([System.tmp_dir!(), "glides_report", "prod"])
  defp local_dir("-" <> env), do: Path.join([System.tmp_dir!(), "glides_report", env])

  defp fetch_local_path(path_prefix, table_name, local_files) do
    file_prefix = Path.basename(path_prefix)
    file_substring = "https_cdn.mbta.com_realtime_#{table_name}_enhanced.json"

    Enum.find(local_files, fn filename ->
      String.starts_with?(filename, file_prefix) and String.contains?(filename, file_substring)
    end)
    |> case do
      nil ->
        {:error, path_prefix}

      filename ->
        IO.inspect("File already exists, skipping download: #{filename}")
        {:ok, filename}
    end
  end

  # Downloads a VehiclePosition or TripUpdate file and returns the local path it was downloaded to.
  defp download_file(remote_prefix, table_name, env_suffix) do
    all_objects =
      ExAws.S3.list_objects("mbta-gtfs-s3#{env_suffix}", prefix: remote_prefix)
      |> ExAws.stream!()
      |> Enum.to_list()

    remote_path =
      Enum.find_value(all_objects, fn obj ->
        if String.contains?(obj.key, "https_cdn.mbta.com_realtime_#{table_name}_enhanced.json"),
          do: obj.key
      end)

    # Files are downloaded to a temp directory.
    local_path =
      remote_path
      |> Path.split()
      |> Enum.take(-1)
      |> then(&Path.join(local_dir(env_suffix), &1))

    IO.inspect("Downloading #{remote_path} to #{local_path}...")

    ExAws.S3.download_file("mbta-gtfs-s3", remote_path, local_path)
    |> ExAws.request()

    local_path
  end

  # Loads a locally-stored file into an ETS table
  defp load_file_into_table(table_name, local_path) do
    json_data =
      File.stream!(local_path, [:compressed])
      |> Jaxon.Stream.from_enumerable()

    timestamp =
      json_data
      |> Jaxon.Stream.query([:root, "header", "timestamp"])
      |> Enum.to_list()
      |> List.first()

    json_data
    |> Jaxon.Stream.query([:root, "entity", :all])
    |> Stream.each(fn obj ->
      :ets.insert(
        table_name,
        {"#{timestamp}_#{obj["id"]}", AtomicMap.convert(obj, safe: false, underscore: false)}
      )
    end)
    |> Stream.run()
  end

  # Creates or clears an ETS table.
  defp set_up_table(table) do
    if :ets.whereis(table) != :undefined,
      do: :ets.delete_all_objects(table),
      else: :ets.new(table, [:named_table, :public])
  end
end
```

Logic to simulate countdown clocks, used by the "next 2 predictions only" filter.

```elixir
defmodule GlidesReport.Sign do
  @moduledoc "Simulates a countdown clock at one platform (child stop ID)."

  @type t :: %__MODULE__{
          predictions: list({trip_id :: String.t(), departure_time :: integer}),
          top_twos: MapSet.t(trip_id :: String.t())
        }

  defstruct predictions: [], top_twos: MapSet.new()

  def new, do: %__MODULE__{}

  def new(trip_id, departure_time, timestamp) when departure_time >= timestamp do
    %__MODULE__{
      predictions: [{trip_id, departure_time}],
      top_twos: MapSet.new([trip_id])
    }
  end

  def new(_trip_id, _departure_time, _timestamp), do: new()

  def apply_skipped_trip(sign, trip_id, timestamp) do
    sign = advance_to_time(sign, timestamp)

    update_in(sign.predictions, fn predictions ->
      Enum.reject(predictions, &match?({^trip_id, _}, &1))
    end)
    |> update_top_twos()
  end

  def apply_stop_time_update(sign, trip_id, departure_time, timestamp) do
    sign = advance_to_time(sign, timestamp)

    update_in(sign.predictions, fn predictions ->
      predictions
      |> replace_or_append(&match?({^trip_id, _}, &1), {trip_id, departure_time})
      |> Enum.sort_by(fn {_, ts} -> ts end)
    end)
    |> update_top_twos()
  end

  def update_top_twos(sign) do
    update_in(sign.top_twos, fn top_twos ->
      sign.predictions
      |> Enum.take(2)
      |> Enum.reduce(top_twos, fn {trip_id, _}, top_twos -> MapSet.put(top_twos, trip_id) end)
    end)
  end

  # Simulate time passing until the next timestamped trip update comes in.
  defp advance_to_time(sign, timestamp) do
    {before, not_before} = Enum.split_while(sign.predictions, fn {_, ts} -> ts < timestamp end)
    seen = before ++ Enum.take(not_before, 2)
    seen_trip_ids = MapSet.new(seen, &elem(&1, 0))

    sign = put_in(sign.predictions, not_before)
    sign = update_in(sign.top_twos, &MapSet.union(&1, seen_trip_ids))
    sign
  end

  defp replace_or_append([], _predicate?, value), do: [value]

  defp replace_or_append([h | t], predicate?, value) do
    if predicate?.(h),
      do: [value | t],
      else: [h | replace_or_append(t, predicate?, value)]
  end
end

defmodule GlidesReport.CountdownClocksSimulation do
  @moduledoc "Simulates countdown clock signs."

  alias GlidesReport.{Sign, Util}

  @type t :: %{(stop_id :: String.t()) => Sign.t()}

  def get_all_top_two_trips(stop_ids, line) do
    trip_updates_for_simulation(stop_ids, line)
    |> Enum.reduce(%{}, fn tr_upd, signs -> apply_trip_update(signs, tr_upd) end)
    |> Stream.map(fn {_stop_id, sign} -> sign.top_twos end)
    |> Enum.reduce(MapSet.new(), &MapSet.union/2)
  end

  def apply_trip_update(signs, tr_upd)
      when tr_upd.trip_update.trip.schedule_relationship == "CANCELED" do
    trip_id = tr_upd.id
    timestamp = tr_upd.trip_update.timestamp

    Map.new(signs, fn {stop_id, sign} ->
      {stop_id, Sign.apply_skipped_trip(sign, trip_id, timestamp)}
    end)
  end

  def apply_trip_update(signs, tr_upd) do
    trip_id = tr_upd.id
    timestamp = tr_upd.trip_update.timestamp

    Enum.reduce(tr_upd.trip_update.stop_time_update, signs, fn
      %{schedule_relationship: "SKIPPED"} = stop_time_update, signs ->
        Map.update(
          signs,
          stop_time_update.stop_id,
          Sign.new(),
          &Sign.apply_skipped_trip(&1, trip_id, timestamp)
        )

      stop_time_update, signs ->
        departure_time = stop_time_update.departure.time

        Map.update(
          signs,
          stop_time_update.stop_id,
          Sign.new(trip_id, departure_time, timestamp),
          &Sign.apply_stop_time_update(&1, trip_id, departure_time, timestamp)
        )
    end)
  end

  defp trip_updates_for_simulation(stop_ids, line) do
    :TripUpdates
    |> Util.stream_values()
    |> Stream.filter(&relevant_trip_update_for_simulation?/1)
    # Apply line filter
    |> Stream.filter(fn tr_upd ->
      line && Util.on_line?(line, tr_upd[:trip_update][:trip][:route_id])
    end)
    # Filter each trip update's stop_time_update list.
    # If a stop filter is set, apply it.
    # Also remove any entries that don't have a .departure.time value.
    # If filtered list is empty for any trip update, the trip update is removed entirely.
    |> Stream.map(&filter_stops_for_simulation(&1, stop_ids))
    |> Stream.reject(&is_nil/1)
    |> Enum.sort_by(& &1.trip_update.timestamp)
  end

  defp relevant_trip_update_for_simulation?(tr_upd) do
    tr_upd[:trip_update][:timestamp] != nil and
      tr_upd[:trip_update][:trip][:revenue]
  end

  defp filter_stops_for_simulation(tr_upd, stop_ids) do
    tr_upd
    |> filter_stops_by_stop_id_for_simulation(stop_ids)
    |> case do
      nil ->
        nil

      tr_upd when tr_upd.trip_update.trip.schedule_relationship == "CANCELED" ->
        tr_upd

      tr_upd ->
        update_in(tr_upd.trip_update.stop_time_update, fn stop_time_update ->
          Enum.reject(stop_time_update, &is_nil(get_in(&1, [:departure, :time])))
        end)
    end
  end

  defp filter_stops_by_stop_id_for_simulation(tr_upd, stop_ids)
       when is_nil(stop_ids)
       when tr_upd.trip_update.trip.schedule_relationship == "CANCELED" do
    tr_upd
  end

  defp filter_stops_by_stop_id_for_simulation(tr_upd, stop_ids) do
    tr_upd.trip_update.stop_time_update
    |> Enum.find(&(&1.stop_id in stop_ids))
    |> case do
      nil ->
        nil

      target_stop_time_update ->
        put_in(tr_upd.trip_update.stop_time_update, [target_stop_time_update])
    end
  end
end
```

## Main procedure

Read inputs.

```elixir
settings =
  GlidesReport.Settings.new(
    env_input,
    date_input,
    line_input,
    stop_ids_input,
    limit_to_next_2_predictions_input
  )
```

Load data into ETS tables.

```elixir
GlidesReport.Loader.load_data(settings.date, settings.env_suffix)
```

Filter trip updates based on user's settings.

```elixir
trip_updates =
  :TripUpdates
  |> GlidesReport.Util.stream_values()
  |> Stream.filter(&GlidesReport.Util.relevant_trip_update?/1)
  # Apply line filter
  |> Stream.filter(fn tr_upd ->
    GlidesReport.Util.on_line?(settings.line, tr_upd.trip_update.trip.route_id)
  end)
  # Filter each trip update's stop_time_update list.
  # If a stop filter is set, apply it.
  # Also remove any entries that don't have a .departure.time value.
  # If filtered list is empty for any trip update, the trip update is removed entirely.
  |> Stream.map(&GlidesReport.Util.filter_stops(&1, settings.stop_ids))
  |> Stream.reject(&is_nil/1)

trip_updates =
  if settings.limit_to_next_2_predictions do
    top_twos =
      GlidesReport.CountdownClocksSimulation.get_all_top_two_trips(
        settings.stop_ids,
        settings.line
      )

    Stream.filter(trip_updates, &(&1.id in top_twos))
  else
    trip_updates
  end
```

Filter vehicle positions based on user's settings.

```elixir
vehicle_positions =
  :VehiclePositions
  |> GlidesReport.Util.stream_values()
  |> Stream.filter(&GlidesReport.Util.relevant_vehicle_position?/1)
  |> Stream.filter(fn ve_pos ->
    GlidesReport.Util.on_line?(settings.line, ve_pos.vehicle.trip.route_id)
  end)
  |> Stream.filter(fn ve_pos ->
    GlidesReport.Util.vehicle_departing_target_stop?(
      ve_pos.vehicle.stop_id,
      settings.stop_ids
    )
  end)
```

## Per-Hour Counts of trips for which RTR made departure predictions vs. actual departures

Methodology:

* From VehiclePositions, get all timestamps (truncated to minute) at which a vehicle actually departed a stop.[^1]
* From TripUpdates, get all timestamps (truncated to minute) at which a vehicle was predicted to depart a stop.[^2]

---

[^1]: There is no "departing stop" vehicle status, so we look for events where the vehicle is "IN_TRANSIT_TO" the stop _after_ the target stop.
[^2]: This is the set of _all_ times at which a vehicle was predicted to depart a stop. If at any moment, even just for a minute, a vehicle was predicted to depart stop S at time T, then that `{time, stop}` pair is added to the set.

```elixir
predicted_first_stop_departure_times_by_hour =
  trip_updates
  # Group by hour of the predicted departure (not hour the prediction was generated!),
  # in local time.
  # This requires splitting each trip update into its individual stop_time_update items.
  |> Stream.flat_map(fn tr_upd ->
    Enum.map(
      tr_upd.trip_update.stop_time_update,
      &{&1.stop_id, &1.departure.time}
    )
  end)
  |> Enum.group_by(
    fn {_first_stop_id, timestamp} ->
      GlidesReport.Util.unix_timestamp_to_local_hour(timestamp)
    end,
    fn {first_stop_id, timestamp} ->
      {first_stop_id, GlidesReport.Util.unix_timestamp_to_local_minute(timestamp)}
    end
  )
  |> Map.new(fn {hour, first_stop_minutes} -> {hour, MapSet.new(first_stop_minutes)} end)

actual_next_stop_in_transit_to_times_by_hour =
  vehicle_positions
  # Group by hour
  |> Stream.map(&{&1.vehicle.stop_id, &1.vehicle.timestamp})
  |> Enum.group_by(
    fn {_next_stop_id, timestamp} ->
      GlidesReport.Util.unix_timestamp_to_local_hour(timestamp)
    end,
    fn {next_stop_id, timestamp} ->
      {next_stop_id, GlidesReport.Util.unix_timestamp_to_local_minute(timestamp)}
    end
  )
  |> Map.new(fn {hour, next_stop_minutes} -> {hour, MapSet.new(next_stop_minutes)} end)

table =
  0..23
  # Service day starts at 4am, so let's start the table at that hour.
  |> Enum.map(&rem(&1 + 4, 24))
  |> Enum.map(fn hour ->
    predicted_first_stop_departure_times =
      Map.get(predicted_first_stop_departure_times_by_hour, hour, MapSet.new())

    actual_next_stop_in_transit_to_times =
      Map.get(actual_next_stop_in_transit_to_times_by_hour, hour, MapSet.new())

    predicted_departure_time_count = MapSet.size(predicted_first_stop_departure_times)
    actual_departure_time_count = MapSet.size(actual_next_stop_in_transit_to_times)

    # Number of departure times that were both predicted and actually happened.
    #
    # Need to do a custom set intersection for this, because we need to relate first_stops in
    # predictions with next_stops in actuals, and the relation is many:1.
    actual_AND_predicted_departure_time_count =
      Enum.count(actual_next_stop_in_transit_to_times, fn {next_stop_id, minute} ->
        valid_first_stop_ids = Map.fetch!(next_to_first_stop, next_stop_id)

        Enum.any?(valid_first_stop_ids, fn id ->
          {id, minute} in predicted_first_stop_departure_times
        end)
      end)

    percentage =
      if actual_departure_time_count > 0 do
        p =
          round(100.0 * (actual_AND_predicted_departure_time_count / actual_departure_time_count))

        "#{p}%"
      else
        "N/A (0 actual departures)"
      end

    [
      {"hour", "#{GlidesReport.Util.zero_pad(hour)}:00"},
      {"# of predicted departure times", predicted_departure_time_count},
      {"# of actual departure times", actual_departure_time_count},
      {"% of actual departure times that were also predicted", percentage}
    ]
  end)

table_name = "Predicted vs actual departures"

Kino.Download.new(
  fn -> GlidesReport.Util.table_to_csv(table) end,
  filename: GlidesReport.Util.build_csv_name(table_name, settings),
  label: "Export as CSV"
)
|> Kino.render()

Kino.DataTable.new(table, name: table_name)
```

## Data Structure

Some typespecs to document the data structures we're working with.

```elixir
defmodule Common do
  @moduledoc "Shared types."

  @type stop_id :: String.t()
  @type route_id :: String.t()
  @type trip_id :: String.t()
  @type vehicle_id :: String.t()

  # Unix epoch timestamp
  @type timestamp :: integer

  # e.g. "20240603"
  @type date_string :: String.t()

  # e.g. "09:18:50"
  @type time_string :: String.t()
end

defmodule TripUpdate do
  @moduledoc "Structure of an entry in the :TripUpdates table."

  @type t :: {key, value}

  # Key is a string of the form "#{timestamp}_#{trip_id}"
  # e.g. "1717524600_62216363"
  # NB: This timestamp can be different from .trip_update.timestamp,
  # it appears to be the time this snapshot was stored while
  # .trip_update.timestamp is the time that the trip update was generated.
  @type key :: String.t()

  @type value :: %{
          # ID of trip being updated.
          id: Common.trip_id(),
          trip_update: %{
            optional(:vehicle) => %{id: Common.vehicle_id()},
            optional(:update_type) => update_type,
            # Time at which this trip update was generated.
            # Field *sometimes* not present if trip.schedule_relationship is "CANCELED"
            # Field not present if update_type is "reverse_trip"
            optional(:timestamp) => Commmon.timestamp(),
            # Field not present if trip.schedule_relationship is "CANCELED"
            optional(:stop_time_update) => [
              %{
                # Field not present if schedule_relationship is "SKIPPED"
                optional(:departure) => %{time: Commmon.timestamp(), uncertainty: integer},
                # Field not present if schedule_relationship is "SKIPPED"
                optional(:arrival) => %{time: Commmon.timestamp(), uncertainty: integer},
                optional(:schedule_relationship) => stop_time_schedule_relationship,
                stop_id: Commmon.stop_id(),
                # index of this stop in the sequence, starting with 1
                stop_sequence: pos_integer
              }
            ],
            trip: %{
              optional(:schedule_relationship) => trip_schedule_relationship,
              trip_id: Commmon.trip_id(),
              direction_id: 0 | 1,
              last_trip: boolean,
              revenue: boolean,
              route_id: Commmon.route_id(),
              start_date: Commmon.date_string(),
              start_time: Commmon.time_string()
            }
          }
        }

  # "mid_trip" | "reverse_trip" | "at_terminal"
  @type update_type :: String.t()

  @type trip_update_id :: String.t()

  # "CANCELED" | "ADDED"
  @type trip_schedule_relationship :: String.t()

  # "SKIPPED"
  @type stop_time_schedule_relationship :: String.t()
end

defmodule VehiclePosition do
  @moduledoc "Structure of an entry in the :VehiclePositions table."

  @type t :: {key, value}

  # Key is a string of the form "#{timestamp}_#{vehicle_id}"
  # e.g. "1717471500_G-10351"
  @type key :: String.t()

  @type value :: %{
          # Same ID as in the second part of key
          # e.g. "G-10351"
          id: Common.vehicle_id(),
          vehicle: %{
            optional(:stop_id) => Commmon.stop_id(),
            # unused for this report
            optional(:multi_carriage_details) => [
              %{
                # index of this carriage in the sequence, starting with 1
                carriage_sequence: pos_integer,
                # carriage ID maybe?
                label: String.t(),
                occupancy_status: occupancy_status,
                orientation: carriage_orientation
              }
            ],
            current_status: status,
            # index of the stop it's at or approaching
            current_stop_sequence: integer,
            # unused for this report
            position: %{
              # compass direction in degrees
              bearing: integer,
              latitude: float,
              longitude: float,
              speed: float
            },
            timestamp: Commmon.timestamp(),
            trip: %{
              direction_id: 0 | 1,
              last_trip: boolean,
              revenue: boolean,
              route_id: Commmon.route_id(),
              schedule_relationship: String.t(),
              start_date: Commmon.date_string(),
              start_time: Commmon.time_string(),
              trip_id: Commmon.trip_id()
            },
            vehicle: %{
              id: Common.vehicle_id(),
              # Formed by joining multi_carriage_details[].label with "-"
              # e.g. "3682-3849"
              label: String.t()
            }
          }
        }

  # "IN_TRANSIT_TO" | "STOPPED_AT" | "INCOMING_AT"
  @type status :: String.t()

  # "NO_DATA_AVAILABLE" | "STANDING_ROOM_ONLY" | "FEW_SEATS_AVAILABLE"
  # | "MANY_SEATS_AVAILABLE" | "CRUSHED_STANDING_ROOM_ONLY"
  @type occupancy_status :: String.t()

  # "AB" | "BA"
  @type carriage_orientation :: String.t()
end
```

<!-- livebook:{"offset":30281,"stamp":{"token":"XCP.WmdJrkpoLtnZCEKqcCRmgAxKOpE-Np-zL8-GorXv5Xa_EtJQ0wgKH659dCm1oRyfGmucWiKigBLmllSQEZuvaPFQTx1qxBJAk3pJyzdBiy4LM2KucZSjq0u15j1zswfs52hWCPeWZ75_sKeLWwuDSdlK4XylcQ","version":2}} -->
