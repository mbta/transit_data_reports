# Glides Terminal Missed/Extraneous Predictions

```elixir
project_dir = __DIR__ |> Path.join("..") |> Path.expand()

Mix.install(
  [
    {:kino, "~> 0.12.0"},
    {:transit_data, path: project_dir},
    # transit_data needs a timezone DB for some date-related logic.
    {:tz, "~> 0.26.5"},
  ],
  config: [
    elixir: [time_zone_database: Tz.TimeZoneDatabase],
    ex_aws: [
      access_key_id: System.get_env("LB_AWS_ACCESS_KEY_ID"),
      secret_access_key: System.get_env("LB_AWS_SECRET_ACCESS_KEY"),
      region: "us-east-1"
    ]
  ]
)

alias TransitData.GlidesReport

Kino.nothing()
```

## Instructions

This notebook provides an implementation of [Rethinking Prediction Accuracy for Glides](https://www.notion.so/mbta-downtown-crossing/Rethinking-Prediction-Accuracy-for-Glides-e99561127b01490689135ab6b70cd33c).

The notebook requires AWS credentials for a user with access to the `mbta-gtfs-s3` family of S3 buckets.

<details>
<summary><kbd><strong>How to add your AWS credentials</strong></kbd></summary>
<br/>

---

1. Open your Hub. [This link](/hub/personal-hub) should send you there.
1. Under "Secrets", add two secrets with the following names:
   - AWS_ACCESS_KEY_ID
   - AWS_SECRET_ACCESS_KEY
1. Return to this notebook. Click the ðŸ”’ icon in the left sidebar and toggle on both secrets.

---
</details>

### Generating a report

Evaluate code cells from top to bottom.

Some cells produce controls that let you adjust how the report runs.

Cells that generate inputs / outputs are marked with a "ðŸ‘‰"â€”you can skip to these, and when you evaluate them, any intermediate cells will automatically evaluate as well.

**Tip:** If you want to generate another report with different settings, simply change the settings, scroll back down to [**Results**](#results), and click "Evaluate" again.

## Setup

### ðŸ‘‰ What data do you want to load?

```elixir
env_input =
  Kino.Input.select("Environment", [
    {"", "prod"},
    {"-dev-blue", "dev-blue"},
    {"-dev-green", "dev-green"},
    {"-dev", "dev"},
    {"-sandbox", "sandbox"}
  ])

today_date =
  DateTime.now!("America/New_York")
  |> DateTime.to_date()

yesterday_date = Date.add(today_date, -1)

# Default setting: Analyze a full service day, starting at 4am yesterday (Eastern) and ending at 4am today (Eastern).
yesterday_start_time =
  DateTime.new!(yesterday_date, ~T[04:00:00], "America/New_York")
  |> DateTime.shift_zone!("Etc/UTC")
  |> DateTime.to_naive()

today_end_time =
  DateTime.new!(today_date, ~T[03:59:59], "America/New_York")
  |> DateTime.shift_zone!("Etc/UTC")
  |> DateTime.to_naive()

start_date_input =
  Kino.Input.utc_datetime("Analyze data from...",
    default: yesterday_start_time,
    max: DateTime.utc_now()
  )

end_date_input =
  Kino.Input.utc_datetime("to...", default: today_end_time, max: DateTime.utc_now())

sample_rate_input =
  Kino.Input.range("Sample data at (?)-minute intervals", min: 1, max: 5, step: 1, default: 5)

samples_per_minute_input =
  Kino.Input.number("Take (?) samples per minute - leave blank for ALL", default: 1)

Kino.Layout.grid(
  [
    env_input,
    Kino.Layout.grid(
      [
        start_date_input,
        end_date_input,
        sample_rate_input,
        samples_per_minute_input
      ],
      columns: 2
    )
  ],
  columns: 1
)
```

### Setting Details

| Setting                             | Details                                                                                                                                                                                              |
| ----------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Environment                         | Environment to analyze data from.                                                                                                                                                                    |
| Date                                | Service date to analyze data from. A 24-hour period starting at 4am Eastern.                                                                                                                         |
| Sample data at (?)-minute intervals | Sets interval at which data is sampled for analysis.<br/>Lower value = more samples and slower report generation.                                                                                    |
| Take (?) samples per minute         | Sets number of samples to take within each sampled minute.<br/>Higher value = more samples and slower report generation.<br/>Leave blank to analyze *all* data within each sampled minute. (slowest) |

<!-- livebook:{"break_markdown":true} -->

Read inputs.

```elixir
start_dt = Kino.Input.read(start_date_input)
end_dt = Kino.Input.read(end_date_input)

if is_nil(start_dt) do
  Kino.interrupt!(:error, "A start date/time must be selected.")
end

if is_nil(end_dt) do
  Kino.interrupt!(:error, "An end date/time must be selected.")
end

if NaiveDateTime.diff(end_dt, start_dt, :hour) >= 24 do
  Kino.interrupt!(
    :error,
    "Sorry, time windows of 24 hours or more are not yet supported.\n" <>
      "(If this was unexpected, check whether the window includes the autumn DST change.)"
  )
end

if NaiveDateTime.diff(end_dt, start_dt) <= 0 do
  Kino.interrupt!(:error, "Start date needs to come before end date.")
end

sample_count = Kino.Input.read(samples_per_minute_input)

if is_integer(sample_count) and sample_count <= 0 do
  Kino.interrupt!(:error, "Samples per minute must be either blank or a positive integer.")
end

loader_settings =
  GlidesReport.Settings.Load.new(
    Kino.Input.read(env_input),
    Kino.Input.read(start_date_input),
    Kino.Input.read(end_date_input),
    Kino.Input.read(sample_rate_input),
    Kino.Input.read(samples_per_minute_input)
  )
```

Load data into memory.

```elixir
file_counts =
  GlidesReport.Loader.load_data(
    loader_settings.start_dt,
    loader_settings.end_dt,
    loader_settings.env_suffix,
    loader_settings.sample_rate,
    loader_settings.sample_count
  )

IO.puts("Found #{file_counts.local} existing local files.")
IO.puts("Downloaded #{file_counts.downloaded} new files.")

# Uncomment to inspect the ETS tables:
# Kino.Layout.grid([
#   Kino.ETS.new(:TripUpdates),
#   Kino.ETS.new(:VehiclePositions)
# ], columns: 2)
Kino.nothing()
```

### ðŸ‘‰ Now, choose how you want to filter the data.

```elixir
stop_ids_input =
  Kino.Input.select("Stop(s)", GlidesReport.Terminals.all_labeled_stops_and_groups())

limit_to_next_2_predictions_input = Kino.Input.checkbox("Simulate countdown clocks?")

min_advance_notice_input = Kino.Input.number("Minimum advance notice (seconds)")

[
  stop_ids_input,
  limit_to_next_2_predictions_input,
  min_advance_notice_input
]
|> Kino.Layout.grid(columns: 3)
```

### Setting Details

| Setting                          | Details                                                                                                                                                                                                                                                                                                                                 |
| -------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Stop(s)                          | Only analyze data concerning a specific stop, or group of stops.<br/><br/>**Note: Terminals that do not have Glides predictionsâ€”Heath Street and Ashmontâ€”are ignored regardless of which stop(s) you select.**                                                                                                                      |
| Simulate countdown clocks?       | Only consider predictions that would have appeared on countdown clocksâ€”those that were in the next 2 predictions for a stop at some point.                                                                                                                                                                                            |
| Minimum advance notice (seconds) | Only consider predictions created at least this many seconds in advance of the departure time they predict.<br/><br/>For example: If this were set to `60`, then a prediction generated at 12:00:00, with departure time predicted for 12:00:59, would be omitted from analysis.<br/><br/>Leave the field blank to disable this filter. |

<!-- livebook:{"break_markdown":true} -->

Read inputs.

```elixir
filter_settings =
  GlidesReport.Settings.Filter.new(
    Kino.Input.read(stop_ids_input),
    Kino.Input.read(limit_to_next_2_predictions_input),
    Kino.Input.read(min_advance_notice_input)
  )
```

## Main procedure

Filter trip updates based on your settings.

```elixir
trip_updates =
  :TripUpdates
  |> GlidesReport.Util.stream_values()
  |> Stream.map(&GlidesReport.TripUpdate.normalize_stop_ids/1)
  # Filter each trip update's stop_time_update list.
  # If filtered list is empty for any trip update, the trip update is removed entirely.
  |> Stream.map(&GlidesReport.TripUpdate.filter_stops(&1, filter_settings.stop_ids))
  |> Stream.reject(&is_nil/1)
  |> Stream.map(
    &GlidesReport.TripUpdate.filter_by_advance_notice(&1, filter_settings.min_advance_notice_sec)
  )
  |> Stream.reject(&is_nil/1)

top_twos =
  if filter_settings.limit_to_next_2_predictions do
    GlidesReport.CountdownClocksSimulation.get_all_top_two_times(filter_settings.stop_ids)
  else
    nil
  end

Kino.nothing()
```

Filter vehicle positions based on your settings.

```elixir
vehicle_positions =
  :VehiclePositions
  |> GlidesReport.Util.stream_values()
  |> Stream.map(&GlidesReport.VehiclePosition.normalize_stop_id/1)
  |> Stream.filter(&(&1.vehicle.stop_id in filter_settings.stop_ids))
  |> GlidesReport.VehiclePosition.dedup_statuses()

Kino.nothing()
```

Compute sets of predicted departure times and sets of actual departure times,

```elixir
predicted_departure_times_by_hour =
  trip_updates
  # Group by hour of the predicted departure (not hour the prediction was generated!),
  # in local time.
  # This requires splitting each trip update into its individual stop_time_update items.
  |> Stream.flat_map(fn tr_upd ->
    Enum.map(
      tr_upd.trip_update.stop_time_update,
      &{&1.stop_id, &1.departure.time}
    )
  end)
  |> then(fn stream ->
    if not is_nil(top_twos) do
      Stream.filter(stream, &(&1 in top_twos))
    else
      stream
    end
  end)
  |> GlidesReport.Util.group_by_hour()

actual_departure_times_by_hour =
  vehicle_positions
  |> Stream.map(&{&1.vehicle.stop_id, &1.vehicle.timestamp})
  |> GlidesReport.Util.group_by_hour()

predicted_percentages_by_hour =
  0..23
  |> Map.new(fn hour ->
    predicted_departure_times = Map.get(predicted_departure_times_by_hour, hour, MapSet.new())

    actual_departure_times = Map.get(actual_departure_times_by_hour, hour, MapSet.new())

    actual_departure_time_count = MapSet.size(actual_departure_times)

    # Number of departure times that were both predicted and actually happened.
    actual_AND_predicted_departure_time_count =
      MapSet.intersection(predicted_departure_times, actual_departure_times)
      |> MapSet.size()

    percentage =
      if actual_departure_time_count > 0 do
        p =
          round(100.0 * (actual_AND_predicted_departure_time_count / actual_departure_time_count))

        "#{p}%"
      else
        "N/A (0 actual departures)"
      end

    {hour, percentage}
  end)

Kino.nothing()
```

## ðŸ‘‰ Results

### Per-Hour Counts of trips for which RTR made departure predictions vs. actual departures

Methodology:

* From VehiclePositions, get all timestamps (truncated to minute) at which a vehicle actually departed a stop.[^1]
* From TripUpdates, get all timestamps (truncated to minute) at which a vehicle was predicted to depart a stop.[^2]
* If a vehicle actually departed stop S at the same minute that a vehicle was predicted to depart stop S, then that prediction is considered accurate.

---

[^1]: There is no "departing stop" vehicle status, so we look for events where the vehicle is "IN_TRANSIT_TO" or "INCOMING_AT" the stop _after_ the target stop.
[^2]: This is the set of _all_ times at which a vehicle was predicted to depart a stop. If at any moment, even just for a minute, a vehicle was predicted to depart stop S at time T, then that `{time, stop}` pair is added to the set.

```elixir
table =
  0..23
  # Service day starts at 4am, so let's start the table at that hour.
  |> Enum.map(&rem(&1 + 4, 24))
  |> Enum.map(fn hour ->
    predicted_departure_time_count =
      predicted_departure_times_by_hour
      |> Map.get(hour, MapSet.new())
      |> MapSet.size()

    actual_departure_time_count =
      actual_departure_times_by_hour
      |> Map.get(hour, MapSet.new())
      |> MapSet.size()

    percentage = Map.fetch!(predicted_percentages_by_hour, hour)

    [
      {"hour", "#{GlidesReport.Util.zero_pad(hour)}:00"},
      {"# of predicted departure times", predicted_departure_time_count},
      {"# of actual departure times", actual_departure_time_count},
      {"% of actual departure times that were also predicted", percentage}
    ]
  end)

table_name = "Predicted vs actual departures"

Kino.Markdown.new("""
### ðŸ“£ Please note:

**The last table column is significantly affected by the sample rate / samples-per-minute settings.**

Percentage will increase with more samples taken.

---
""")
|> Kino.render()

Kino.Download.new(
  fn -> GlidesReport.Util.table_to_csv(table) end,
  filename: GlidesReport.Util.build_csv_name(table_name, loader_settings, filter_settings),
  label: "Export as CSV"
)
|> Kino.render()

Kino.DataTable.new(table, name: table_name)
```

<!-- livebook:{"offset":14086,"stamp":{"token":"XCP.EA7CphXHatF57SUKbDN1_xwoECJf2zQtkzTZAwVtkCKHkYF05WxoXKv3L-FRHpz5leYZYhftdaWMgKAWzGXV_PZsbLa2SiXqSeeZpoXnasBc531fQiainqMYKoRE6vprYImgFriH78iBm8MHZVUA7NGB9w8g5w","version":2}} -->
